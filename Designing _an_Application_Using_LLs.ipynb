{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d6acad",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "#### The goal of this notebook is to propose an application design that utilizes large-scale language models to enhance the interaction experience between humans and AI. The focus is on the design concept, aimed at showcasing its potential in learning and cultural exchange."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7991fad7",
   "metadata": {},
   "source": [
    "## What you will find here?\n",
    "- A brief introduction to large language models and their common usage methods\n",
    "- Application scenario design, including target users, core functions, and interaction processes.\n",
    "- Conduct a critical analysis of the social and cultural impact of the design, covering both positive effects and potential risks.\n",
    "- Simple prototype & interaction diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730c9e0",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Background on Large Language Models (LLMs)\n",
    "\n",
    "Large Language Models (LLMs) represent a major advancement in natural language processing. They are trained on massive datasets to understand and generate human-like text, enabling applications in education, creativity, and cultural engagement.\n",
    "\n",
    "### 1.1 Common Ways to Use LLMs\n",
    "1. **Through an API**  \n",
    "   - Example: OpenAI’s GPT-4 API or HuggingFace’s model endpoints.  \n",
    "   - Requires coding skills and often incurs costs.  \n",
    "   - Tools like ChatGPT, Microsoft Copilot, or Gemini integrate LLMs into user-friendly interfaces.\n",
    "   - No coding required, but limited customization.\n",
    "\n",
    "3. **Standalone Executable Models**  \n",
    "   - Example: Llamafile or Ollama, which allow running models locally.\n",
    "   - Useful for privacy and offline use.\n",
    "\n",
    "4. **Community Platforms**  \n",
    "   - [HuggingFace Spaces]ready-to-use demos and collaborative environments.\n",
    "\n",
    "\n",
    "### 1.2 Key Considerations\n",
    "- **Data Privacy**  \n",
    "  It’s unclear how services like ChatGPT handle user data. Transparency is limited.  \n",
    "- **Model Size vs. Efficiency**:Bigger models are not always better. Initiatives like \n",
    "\n",
    "\n",
    "### 1.3 Why this Matters for Design?\n",
    "Understanding these aspects helps you design an application that:\n",
    "- Leverages LLM capabilities effectively.\n",
    "- Addresses ethical concerns (privacy, bias).\n",
    "- Promotes inclusivity and cultural diversity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae484f57",
   "metadata": {},
   "source": [
    "# 2.Application design： e.g. Historical story generator\n",
    "\n",
    "\n",
    "### Overview\n",
    "The proposed application uses a Large Language Model (LLM) to generate historically inspired narratives based on user-selected cultures, time periods, and themes. The goal is to **promote cultural diversity, historical awareness, and ethical storytelling** while mitigating bias and ensuring inclusivity.\n",
    "\n",
    "\n",
    "### Target Audience\n",
    "- **Educators and Students**: For history and cultural studies.\n",
    "- **Writers and Artists**: Seeking inspiration for creative projects.\n",
    "- **Community Organizations**: Preserving local traditions and oral histories.\n",
    "\n",
    "\n",
    "### Core Features\n",
    "- **Culturally Sensitive Story Generation**: Users input a historical period and cultural context (e.g., \"World War II in Germany\"). The LLM generates a narrative that avoids stereotypes and reflects authentic cultural values.\n",
    "- **Language Support**: Stories can be generated in multiple languages.\n",
    "- **Educational Mode**: Provides historical context alongside generated stories, encouraging critical thinking rather than passive consumption.\n",
    "\n",
    "\n",
    "### Interaction Flow\n",
    "- 1. User selects historical period & culture\n",
    "- 2. Choose language & tone\n",
    "- 3. LLM generates culturally aligned story\n",
    "- 4. [Optional: Display historical context & references]\n",
    "- 5. User feedback loop for bias detection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d33d5",
   "metadata": {},
   "source": [
    "# 3.Prototype demo：Generate a Historical Story\n",
    "\n",
    "This section demonstrates a simple prototype of the **Historical Story Generator**.  \n",
    "It will:\n",
    "1. Ask the user for a historical period and cultural context.\n",
    "2. Generate a culturally aligned story using an LLM.\n",
    "3. Display the story in plain text.\n",
    "\n",
    "\n",
    "### Step 1: Install Required Libraries\n",
    "We need the `openai` library to interact with GPT models. Run the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68bf0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.9.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-2.9.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, pydantic-core, jiter, distro, annotated-types, pydantic, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [openai]2m7/8\u001b[0m [openai]c]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.12.0 openai-2.9.0 pydantic-2.12.5 pydantic-core-2.41.5 tqdm-4.67.1 typing-inspection-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a1e5a",
   "metadata": {},
   "source": [
    "### Step 2: Set Up API Key\n",
    "Store your OpenAI API key securely using environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8dc9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set your OpenAI API key securely\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_open_ai_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436706e8",
   "metadata": {},
   "source": [
    "### Step 3: Collect User Input\n",
    "Ask the user for historical context and language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8258841",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Collect user input for historical context\n",
    "period = input(\"Enter a historical period (e.g., 'World War II'): \")\n",
    "culture = input(\"Enter a cultural context (e.g., 'Germany'): \")\n",
    "language = input(\"Enter language (e.g., 'English'): \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e944b4e",
   "metadata": {},
   "source": [
    "### Step 4: Generate Story\n",
    "Use OpenAI's GPT model to create a culturally sensitive story. Run the following command: **Make sure you have the access to gpt-4!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "367f65bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWrite a culturally sensitive historical story about \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperiod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mculture\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Language: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Avoid stereotypes and include authentic cultural details.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Call GPT-4 model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m.completions.create(\n\u001b[32m     10\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     messages=[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: prompt}],\n\u001b[32m     12\u001b[39m     temperature=\u001b[32m0.7\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Extract and print the generated story\u001b[39;00m\n\u001b[32m     16\u001b[39m story = response.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client with your API key\n",
    "client = OpenAIapi_key=\"open_ai_key\"\n",
    "# Create the prompt based on user input\n",
    "prompt = f\"Write a culturally sensitive historical story about {period} in {culture}. Language: {language}. Avoid stereotypes and include authentic cultural details.\"\n",
    "\n",
    "# Call GPT-4 model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Extract and print the generated story\n",
    "story = response.choices[0].message.content\n",
    "print(\"\\nGenerated Story:\\n\")\n",
    "print(story)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f665c",
   "metadata": {},
   "source": [
    "Here is the interaction diagram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09958819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.postimg.cc/x8m5SWzB/Designer.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://i.postimg.cc/x8m5SWzB/Designer.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103dd0fb",
   "metadata": {},
   "source": [
    "# 4. Critical reflection\n",
    "\n",
    "While LLMs offer transformative potential, their design and deployment raise critical ethical and social questions. Below are key concerns supported by recent research.\n",
    "\n",
    "### 4.1 Cultural Bias in Model Outputs\n",
    "LLMs often reflect dominant cultural norms embedded in their training data, which can marginalize underrepresented communities.  \n",
    "> *“We find that the five GPT models’ outputs exhibit a cultural bias towards self-expression values, which include environmental protection and tolerance of diversity, foreigners, gender equality, and different sexual orientations. This cultural bias is remarkably consistent across the five models.”*  \n",
    "— [PNAS Nexus, 2024](https://academic.oup.com/pnasnexus/article/3/9/pgae346/7756548)\n",
    "\n",
    "**Design Implication:** Incorporate cultural prompting and diverse datasets to reduce bias and promote inclusivity.\n",
    "\n",
    "### 4.2 Educational Impact and Critical Thinking\n",
    "Over-reliance on LLMs for programming tasks may undermine students’ problem-solving skills.  \n",
    "> *“The significant inverse correlation associated with code generation and debugging suggests that reliance on LLMs for these critical thinking-intensive activities could be detrimental to students’ ability to independently solve programming tasks. This might imply that while LLMs can be a valuable resource for learning and problem-solving, their use needs to be balanced with the development of independent coding skills.”*  \n",
    "— [MDPI Applied Sciences, 2024](https://www.mdpi.com/2076-3417/14/10/4115)\n",
    "\n",
    "**Design Implication:** Position AI as a supportive tool, not a substitute for cognitive effort.\n",
    "\n",
    "### 4.3 Social Justice and Inclusive Design\n",
    "Data quality and design choices directly affect fairness and equity in AI systems.  \n",
    "> *“Data underlying AI-based technology heavily influences the technology’s quality towards fair decision-making. Compiling data sets from binary, superficial categories without considering the complexity in experiences can thus lead to injustice. From a perspective of social justice, technology design should be inspired by a concern for ethical and social issues such as supporting well-being and reducing inequalities. This requires working in real partnership with local communities and marginalised groups to understand and tackle injustice.”*  \n",
    "— [UNESCO Inclusive Policy Lab, 2023](https://en.unesco.org/inclusivepolicylab/analytics/diversity-technology-design-%E2%80%93-economic-strategy-social-justice-imperative)\n",
    "\n",
    "**Design Implication:** Engage marginalized communities in co-design processes and prioritize ethical considerations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
